"""
è‚¡ç¥¨æœç´¢å·¥å…·æ¨¡å—ï¼ˆä¸²è”å…¥å£ï¼‰

æä¾›Aè‚¡è‚¡ç¥¨æŸ¥è¯¢åŠŸèƒ½çš„ç»Ÿä¸€å…¥å£ï¼Œä¸²è”è°ƒç”¨ï¼š
- stock_data_updater: æ•°æ®æ›´æ–°å·¥å…·
- stock_rising_calculator: è¿ç»­ä¸Šæ¶¨è‚¡ç¥¨è®¡ç®—å·¥å…·
- send_stock_analysis: é£ä¹¦æ¶ˆæ¯å‘é€å·¥å…·

ä¾èµ–ï¼š
    pip install akshare tabulate tqdm langchain-core mcp

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # ç›´æ¥è¿è¡Œ
    python -m agent.stock_searh_tool
    
    # ä½œä¸ºå·¥å…·ä½¿ç”¨
    from agent.stock_searh_tool import search_rising_stocks, get_langchain_tool, get_mcp_tools
    
    # LangChainå·¥å…·
    tool = get_langchain_tool()
    
    # MCPå·¥å…·
    mcp_tools = get_mcp_tools()
"""

import sys
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict

sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.json_util import JsonUtil
from utils.file_util import FileUtil
from utils.log_util import LogUtil

# å¯¼å…¥ç‹¬ç«‹çš„å·¥å…·æ¨¡å—
from agent.stock_data_updater import update_stock_data
from agent.stock_rising_calculator import calculate_rising_stocks
from agent.send_stock_analysis import send_latest_analysis
from agent.stock_concept_analyzer import analyze_concepts

logger = LogUtil.get_logger(__name__)

# ==================== ç›®å½•ç»“æ„å®šä¹‰ ====================
BASE_DIR = Path(__file__).parent.parent
TEMP_DIR = BASE_DIR / ".temp"
OUTPUT_DIR = TEMP_DIR / "output"
TOOLS_OUTPUT_DIR = OUTPUT_DIR / "tools"


# ==================== ä¸»å…¥å£å‡½æ•° ====================

def search_rising_stocks(days: int = 3, market: str = "all", 
                        current_date: Optional[str] = None, 
                        save_result: bool = True, 
                        use_cache: bool = True, 
                        min_increase: float = 10.0, 
                        include_kc: bool = False, 
                        include_cy: bool = False,
                        auto_update_cache: bool = True,
                        send_to_feishu: bool = False) -> Dict:
    """
    æœç´¢è¿ç»­Nå¤©ä¸Šæ¶¨çš„è‚¡ç¥¨ï¼ˆæœåŠ¡ä¸»å…¥å£ï¼‰
    
    ä¸²è”è°ƒç”¨æ•°æ®æ›´æ–°ã€è®¡ç®—å’Œå‘é€åŠŸèƒ½ã€‚
    
    Args:
        days: è¿ç»­ä¸Šæ¶¨å¤©æ•°ï¼Œé»˜è®¤3å¤©
        market: å¸‚åœºç±»å‹ ('all' å…¨å¸‚åœº, 'sh' ä¸Šæµ·, 'sz' æ·±åœ³)
        current_date: æŸ¥è¯¢æ—¥æœŸï¼Œæ ¼å¼YYYYMMDDï¼Œé»˜è®¤ä¸ºä»Šå¤©
        save_result: æ˜¯å¦ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆè¡¨æ ¼mdæ–‡ä»¶ï¼‰
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜çš„æŸ¥è¯¢ç»“æœï¼ˆåŸºäºè¡¨æ ¼mdæ–‡ä»¶ï¼‰
        min_increase: æœ€å°ç´¯è®¡æ¶¨å¹…é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œé»˜è®¤10.0%
        include_kc: æ˜¯å¦åŒ…å«ç§‘åˆ›æ¿ï¼Œé»˜è®¤False
        include_cy: æ˜¯å¦åŒ…å«åˆ›ä¸šæ¿ï¼Œé»˜è®¤False
        auto_update_cache: æ˜¯å¦è‡ªåŠ¨æ›´æ–°ç¼“å­˜ï¼Œé»˜è®¤True
        send_to_feishu: æ˜¯å¦å‘é€åˆ°é£ä¹¦ï¼Œé»˜è®¤False
        
    Returns:
        åŒ…å«æŸ¥è¯¢ç»“æœçš„å­—å…¸ï¼ˆåŒ…å«dataå’Œtableä¸¤ä¸ªå­—æ®µï¼‰
    """
    if current_date is None:
        current_date = datetime.now().strftime("%Y%m%d")
    
    # è¡¨æ ¼æ–‡ä»¶è·¯å¾„
    table_file = TOOLS_OUTPUT_DIR / f"rising_stocks_{current_date}_{days}days_{market}_{min_increase}pct_kc{include_kc}_cy{include_cy}.md"
    
    # æ£€æŸ¥ç¼“å­˜çš„è¡¨æ ¼æ–‡ä»¶
    if use_cache and table_file.exists():
        table_content = FileUtil.read_text(table_file)
        if table_content:
            try:
                # ä»æ–‡ä»¶å†…å®¹ä¸­æå–è‚¡ç¥¨æ•°é‡
                lines = table_content.split('\n')
                title_line = [l for l in lines if 'è‚¡ç¥¨æ•°æ®æ±‡æ€»' in l]
                if title_line:
                    import re
                    match = re.search(r'\((\d+)åª\)', title_line[0])
                    stock_count = int(match.group(1)) if match else 0
                else:
                    stock_count = 0
            except Exception:
                stock_count = 0
            
            # ä»ç¼“å­˜è¯»å–æ—¶ï¼Œé‡æ–°ç”ŸæˆJSONæ•°æ®ï¼ˆä½†ä¸ä¿å­˜ï¼‰
            result_data = {}
            if stock_count > 0:
                from agent.stock_rising_calculator import analyze_rising_stocks
                result_json = analyze_rising_stocks(
                    days=days, market=market, min_increase=min_increase, 
                    include_kc=include_kc, include_cy=include_cy,
                    compress=False
                )
                result_data = JsonUtil.loads(result_json) or {}
            
            return {
                "success": True,
                "message": f"ä»ç¼“å­˜è¯»å–ï¼Œæ‰¾åˆ° {stock_count} åªè¿ç»­{days}å¤©ä¸Šæ¶¨çš„è‚¡ç¥¨ï¼ˆç´¯è®¡æ¶¨å¹…>{min_increase}%ï¼Œç§‘åˆ›æ¿{'åŒ…å«' if include_kc else 'æ’é™¤'}ï¼Œåˆ›ä¸šæ¿{'åŒ…å«' if include_cy else 'æ’é™¤'}ï¼‰",
                "data": result_data,
                "table": table_content,
                "table_path": str(table_file),
                "from_cache": True
            }
    
    # 1. è‡ªåŠ¨æ›´æ–°ç¼“å­˜ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if auto_update_cache:
        update_ok = update_stock_data(days=days + 12, market=market, force_update=False)
        if not update_ok:
            logger.warning("æ•°æ®æ›´æ–°å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œç»§ç»­ä½¿ç”¨ç°æœ‰ç¼“å­˜")
    
    # 2. è®¡ç®—è¿ç»­ä¸Šæ¶¨è‚¡ç¥¨
    result_json, table_content = calculate_rising_stocks(
        days=days, market=market, min_increase=min_increase, 
        include_kc=include_kc, include_cy=include_cy,
        compress=False, save_table=save_result, table_path=table_file if save_result else None
    )
    
    result = JsonUtil.loads(result_json) or {}
    
    if not result.get("stocks"):
        return {
            "success": True,
            "message": f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨æˆ–ç¼“å­˜æ•°æ®ä¸è¶³ï¼ˆç´¯è®¡æ¶¨å¹…>{min_increase}%ï¼Œç§‘åˆ›æ¿{'åŒ…å«' if include_kc else 'æ’é™¤'}ï¼Œåˆ›ä¸šæ¿{'åŒ…å«' if include_cy else 'æ’é™¤'}ï¼‰",
            "data": result,
            "table": table_content,
            "table_path": None,
            "from_cache": False
        }
    
    # 3. å‘é€åˆ°é£ä¹¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if send_to_feishu:
        try:
            send_ok = send_latest_analysis(include_table=True)
            if send_ok:
                logger.info("ç»“æœå·²å‘é€åˆ°é£ä¹¦")
            else:
                logger.warning("é£ä¹¦å‘é€å¤±è´¥")
        except Exception as e:
            logger.error(f"å‘é€åˆ°é£ä¹¦å¤±è´¥: {e}")
    
    return {
        "success": True,
        "message": f"æ‰¾åˆ° {len(result.get('stocks', []))} åªè¿ç»­{result.get('rising_days', days)}å¤©ä¸Šæ¶¨çš„è‚¡ç¥¨ï¼ˆç´¯è®¡æ¶¨å¹…>{min_increase}%ï¼Œç§‘åˆ›æ¿{'åŒ…å«' if include_kc else 'æ’é™¤'}ï¼Œåˆ›ä¸šæ¿{'åŒ…å«' if include_cy else 'æ’é™¤'}ï¼‰",
        "data": result,
        "table": table_content,
        "table_path": str(table_file) if save_result else None,
        "from_cache": False
    }


def search_concepts(days: int = 5, market: str = "all",
                   current_date: Optional[str] = None,
                   save_result: bool = True,
                   use_cache: bool = True,
                   include_kc: bool = False,
                   include_cy: bool = False,
                   auto_update_cache: bool = True,
                   send_to_feishu: bool = False,
                   top_n: int = 20) -> Dict:
    """
    æœç´¢å¤§ç›˜æ¦‚å¿µè¶‹åŠ¿ï¼ˆæœåŠ¡ä¸»å…¥å£ï¼‰
    
    ä¸²è”è°ƒç”¨æ•°æ®æ›´æ–°ã€è®¡ç®—å’Œå‘é€åŠŸèƒ½ã€‚
    
    Args:
        days: åˆ†æå¤©æ•°ï¼Œé»˜è®¤5å¤©
        market: å¸‚åœºç±»å‹ ('all' å…¨å¸‚åœº, 'sh' ä¸Šæµ·, 'sz' æ·±åœ³)
        current_date: æŸ¥è¯¢æ—¥æœŸï¼Œæ ¼å¼YYYYMMDDï¼Œé»˜è®¤ä¸ºä»Šå¤©
        save_result: æ˜¯å¦ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆå›¾è¡¨pngæ–‡ä»¶ï¼‰
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜çš„æŸ¥è¯¢ç»“æœï¼ˆåŸºäºå›¾è¡¨pngæ–‡ä»¶ï¼‰
        include_kc: æ˜¯å¦åŒ…å«ç§‘åˆ›æ¿ï¼Œé»˜è®¤False
        include_cy: æ˜¯å¦åŒ…å«åˆ›ä¸šæ¿ï¼Œé»˜è®¤False
        auto_update_cache: æ˜¯å¦è‡ªåŠ¨æ›´æ–°ç¼“å­˜ï¼Œé»˜è®¤True
        send_to_feishu: æ˜¯å¦å‘é€åˆ°é£ä¹¦ï¼Œé»˜è®¤False
        top_n: æ˜¾ç¤ºå‰Nä¸ªæ¦‚å¿µï¼Œé»˜è®¤20
        
    Returns:
        åŒ…å«æŸ¥è¯¢ç»“æœçš„å­—å…¸ï¼ˆåŒ…å«dataå’Œchartä¸¤ä¸ªå­—æ®µï¼‰
    """
    if current_date is None:
        current_date = datetime.now().strftime("%Y%m%d")
    
    # å›¾è¡¨æ–‡ä»¶è·¯å¾„
    chart_file = TOOLS_OUTPUT_DIR / f"concept_analysis_{current_date}_{days}days_{market}_kc{include_kc}_cy{include_cy}.png"
    
    # æ£€æŸ¥ç¼“å­˜çš„å›¾è¡¨æ–‡ä»¶
    if use_cache and chart_file.exists():
        chart_content = str(chart_file)
        if chart_file.exists():
            try:
                # ä»ç¼“å­˜è¯»å–æ—¶ï¼Œé‡æ–°ç”ŸæˆJSONæ•°æ®ï¼ˆä½†ä¸ä¿å­˜ï¼‰
                result_data = {}
                from agent.stock_concept_analyzer import analyze_concepts_simple
                result_json = analyze_concepts_simple(
                    days=days, market=market,
                    include_kc=include_kc, include_cy=include_cy,
                    compress=False
                )
                result_data = JsonUtil.loads(result_json) or {}
                concept_count = len(result_data.get('concepts', []))
            except Exception:
                concept_count = 0
                result_data = {}
            
            return {
                "success": True,
                "message": f"ä»ç¼“å­˜è¯»å–ï¼Œæ‰¾åˆ° {concept_count} ä¸ªæ¦‚å¿µï¼ˆåˆ†æå‘¨æœŸ{days}å¤©ï¼Œç§‘åˆ›æ¿{'åŒ…å«' if include_kc else 'æ’é™¤'}ï¼Œåˆ›ä¸šæ¿{'åŒ…å«' if include_cy else 'æ’é™¤'}ï¼‰",
                "data": result_data,
                "chart": chart_content,
                "chart_path": str(chart_file),
                "from_cache": True
            }
    
    # 1. è‡ªåŠ¨æ›´æ–°ç¼“å­˜ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if auto_update_cache:
        update_ok = update_stock_data(days=days + 7, market=market, force_update=False)
        if not update_ok:
            logger.warning("æ•°æ®æ›´æ–°å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œç»§ç»­ä½¿ç”¨ç°æœ‰ç¼“å­˜")
    
    # 2. åˆ†ææ¦‚å¿µè¶‹åŠ¿
    result_json, chart_content = analyze_concepts(
        days=days, market=market,
        include_kc=include_kc, include_cy=include_cy,
        compress=False, save_chart=save_result, chart_path=chart_file if save_result else None, top_n=top_n
    )
    
    result = JsonUtil.loads(result_json) or {}
    
    if not result.get("concepts"):
        return {
            "success": True,
            "message": f"æœªæ‰¾åˆ°æ¦‚å¿µæ•°æ®æˆ–ç¼“å­˜æ•°æ®ä¸è¶³ï¼ˆåˆ†æå‘¨æœŸ{days}å¤©ï¼Œç§‘åˆ›æ¿{'åŒ…å«' if include_kc else 'æ’é™¤'}ï¼Œåˆ›ä¸šæ¿{'åŒ…å«' if include_cy else 'æ’é™¤'}ï¼‰",
            "data": result,
            "chart": chart_content,
            "chart_path": None,
            "from_cache": False
        }
    
    # 3. å‘é€åˆ°é£ä¹¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if send_to_feishu:
        try:
            send_ok = send_latest_analysis(include_table=True)
            if send_ok:
                logger.info("ç»“æœå·²å‘é€åˆ°é£ä¹¦")
            else:
                logger.warning("é£ä¹¦å‘é€å¤±è´¥")
        except Exception as e:
            logger.error(f"å‘é€åˆ°é£ä¹¦å¤±è´¥: {e}")
    
    return {
        "success": True,
        "message": f"æ‰¾åˆ° {len(result.get('concepts', []))} ä¸ªæ¦‚å¿µï¼ˆåˆ†æå‘¨æœŸ{result.get('analysis_days', days)}å¤©ï¼Œç§‘åˆ›æ¿{'åŒ…å«' if include_kc else 'æ’é™¤'}ï¼Œåˆ›ä¸šæ¿{'åŒ…å«' if include_cy else 'æ’é™¤'}ï¼‰",
        "data": result,
        "chart": chart_content,
        "chart_path": str(chart_file) if save_result else None,
        "from_cache": False
    }


# ==================== LangChain Tool åŒ…è£… ====================

def get_langchain_tool():
    """
    è·å–LangChainå·¥å…·ï¼ˆä½¿ç”¨æœ€æ–°è¯­æ³•ï¼‰
    
    Returns:
        LangChain Toolå¯¹è±¡åˆ—è¡¨
    """
    try:
        from langchain_core.tools import tool
        
        @tool
        def search_rising_stocks_tool(
            days: int = 3, 
            market: str = "all", 
            min_increase: float = 10.0, 
            include_kc: bool = False, 
            include_cy: bool = False
        ) -> str:
            """
            æœç´¢è¿ç»­Nå¤©ä¸Šæ¶¨çš„Aè‚¡è‚¡ç¥¨ï¼ˆåŸºäºæœ¬åœ°ç¼“å­˜åˆ†æï¼Œè‡ªåŠ¨æ›´æ–°æ•°æ®ï¼‰
            
            åŠŸèƒ½è¯´æ˜ï¼š
            - è‡ªåŠ¨æ£€æŸ¥å¹¶æ›´æ–°è‚¡ç¥¨æ•°æ®ç¼“å­˜ï¼ˆæœ¬åœ°æœ‰æ•°æ®åˆ™è·³è¿‡è¿œç¨‹è°ƒç”¨ï¼‰
            - ä»æœ¬åœ°ç¼“å­˜è¯»å–è‚¡ç¥¨å†å²æ•°æ®ï¼Œåˆ†æè¿ç»­ä¸Šæ¶¨èµ°åŠ¿
            - è‡ªåŠ¨è¿‡æ»¤ST/*STè‚¡ç¥¨ï¼ˆé¿å…é€€å¸‚é£é™©ï¼‰
            - æ”¯æŒæŒ‰å¸‚åœºç­›é€‰ï¼ˆä¸Šäº¤æ‰€/æ·±äº¤æ‰€/ç§‘åˆ›æ¿/åˆ›ä¸šæ¿ï¼‰
            - æŒ‰è¿æ¶¨å¤©æ•°å’Œç´¯è®¡æ¶¨å¹…ç»¼åˆæ’åº
            
            Args:
                days: è¿ç»­ä¸Šæ¶¨å¤©æ•°ï¼Œé»˜è®¤3å¤©ï¼ˆä»æœ€è¿‘ä¸€å¤©å¾€å‰è®¡ç®—ï¼‰
                market: å¸‚åœºç±»å‹ç­›é€‰
                    - "all": å…¨å¸‚åœºï¼ˆé»˜è®¤ï¼‰
                    - "sh": ä¸Šæµ·ä¸»æ¿ï¼ˆæ²ªå¸‚ï¼‰
                    - "sz": æ·±åœ³ä¸»æ¿ï¼ˆæ·±å¸‚ï¼‰
                min_increase: æœ€å°ç´¯è®¡æ¶¨å¹…é˜ˆå€¼ï¼Œé»˜è®¤10.0%ï¼ˆè¿æ¶¨æœŸé—´çš„ç´¯è®¡æ¶¨å¹…ï¼‰
                include_kc: æ˜¯å¦åŒ…å«ç§‘åˆ›æ¿ï¼ˆ688xxxï¼‰ï¼Œé»˜è®¤False
                include_cy: æ˜¯å¦åŒ…å«åˆ›ä¸šæ¿ï¼ˆ300xxxï¼‰ï¼Œé»˜è®¤False
            
            Returns:
                JSONæ ¼å¼çš„è‚¡ç¥¨æœç´¢ç»“æœï¼ˆç”¨äºæ¨¡å‹è¾“å…¥ï¼‰
            """
            logger.info(f"LangChainå·¥å…·è¢«è°ƒç”¨: days={days}, market={market}, min_increase={min_increase}")
            result = search_rising_stocks(
                days=days, 
                market=market, 
                min_increase=min_increase, 
                include_kc=include_kc, 
                include_cy=include_cy,
                auto_update_cache=True
            )
            
            if not result.get("success"):
                return JsonUtil.dumps({"message": result.get("message", "æŸ¥è¯¢å¤±è´¥")})
            
            # è¿”å›JSONæ•°æ®ï¼ˆå‹ç¼©æ ¼å¼ï¼Œå‡å°‘tokenï¼‰
            data = result.get("data", {})
            return JsonUtil.dumps({
                "success": True, 
                "message": result.get("message", ""), 
                "data": data
            })
        
        @tool
        def search_concepts_tool(
            days: int = 5,
            market: str = "all",
            include_kc: bool = False,
            include_cy: bool = False
        ) -> str:
            """
            åˆ†æå¤§ç›˜æ¦‚å¿µè¶‹åŠ¿ï¼ˆåŸºäºæœ¬åœ°ç¼“å­˜åˆ†æï¼Œè‡ªåŠ¨æ›´æ–°æ•°æ®ï¼‰
            
            åŠŸèƒ½è¯´æ˜ï¼š
            - è‡ªåŠ¨æ£€æŸ¥å¹¶æ›´æ–°è‚¡ç¥¨æ•°æ®ç¼“å­˜ï¼ˆæœ¬åœ°æœ‰æ•°æ®åˆ™è·³è¿‡è¿œç¨‹è°ƒç”¨ï¼‰
            - ä»æœ¬åœ°ç¼“å­˜è¯»å–è‚¡ç¥¨å†å²æ•°æ®ï¼Œåˆ†ææ¦‚å¿µæ¿å—è¶‹åŠ¿
            - è‡ªåŠ¨è¿‡æ»¤ST/*STè‚¡ç¥¨ï¼ˆé¿å…é€€å¸‚é£é™©ï¼‰
            - æ”¯æŒæŒ‰å¸‚åœºç­›é€‰ï¼ˆä¸Šäº¤æ‰€/æ·±äº¤æ‰€/ç§‘åˆ›æ¿/åˆ›ä¸šæ¿ï¼‰
            - æŒ‰ç´¯è®¡å¹³å‡æ¶¨è·Œå¹…æ’åºï¼Œå®šä½å¤§ç›˜ä¸»çº¿è¶‹åŠ¿
            - ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å±•ç¤ºTopæ¦‚å¿µè¶‹åŠ¿
            
            Args:
                days: åˆ†æå¤©æ•°ï¼Œé»˜è®¤5å¤©ï¼ˆæœ€è¿‘Nä¸ªäº¤æ˜“æ—¥ï¼‰
                market: å¸‚åœºç±»å‹ç­›é€‰
                    - "all": å…¨å¸‚åœºï¼ˆé»˜è®¤ï¼‰
                    - "sh": ä¸Šæµ·ä¸»æ¿ï¼ˆæ²ªå¸‚ï¼‰
                    - "sz": æ·±åœ³ä¸»æ¿ï¼ˆæ·±å¸‚ï¼‰
                include_kc: æ˜¯å¦åŒ…å«ç§‘åˆ›æ¿ï¼ˆ688xxxï¼‰ï¼Œé»˜è®¤False
                include_cy: æ˜¯å¦åŒ…å«åˆ›ä¸šæ¿ï¼ˆ300xxxï¼‰ï¼Œé»˜è®¤False
            
            Returns:
                JSONæ ¼å¼çš„æ¦‚å¿µåˆ†æç»“æœï¼ˆç”¨äºæ¨¡å‹è¾“å…¥ï¼‰
            """
            logger.info(f"LangChainå·¥å…·è¢«è°ƒç”¨: days={days}, market={market}")
            result = search_concepts(
                days=days,
                market=market,
                include_kc=include_kc,
                include_cy=include_cy,
                auto_update_cache=True
            )
            
            if not result.get("success"):
                return JsonUtil.dumps({"message": result.get("message", "æŸ¥è¯¢å¤±è´¥")})
            
            # è¿”å›JSONæ•°æ®ï¼ˆå‹ç¼©æ ¼å¼ï¼Œå‡å°‘tokenï¼‰
            data = result.get("data", {})
            return JsonUtil.dumps({
                "success": True,
                "message": result.get("message", ""),
                "data": data
            })
        
        return [search_rising_stocks_tool, search_concepts_tool]
    except ImportError:
        logger.error("langchain_coreæœªå®‰è£…ï¼Œæ— æ³•åˆ›å»ºLangChainå·¥å…·")
        return None


# ==================== MCP Server åŒ…è£… ====================

def get_mcp_tools() -> list:
    """
    è·å–MCPå·¥å…·åˆ—è¡¨
    
    Returns:
        MCPå·¥å…·åˆ—è¡¨
    """
    from agent.stock_data_updater import get_mcp_tool as get_updater_tool
    from agent.stock_rising_calculator import get_mcp_tool as get_calculator_tool
    from agent.stock_concept_analyzer import get_mcp_tool as get_analyzer_tool
    
    return [
        get_updater_tool(),
        get_calculator_tool(),
        get_analyzer_tool()
    ]


def handle_mcp_call(tool_name: str, arguments: Dict) -> Dict:
    """
    å¤„ç†MCPå·¥å…·è°ƒç”¨
    
    Args:
        tool_name: å·¥å…·åç§°
        arguments: å·¥å…·å‚æ•°
        
    Returns:
        å·¥å…·æ‰§è¡Œç»“æœ
    """
    from agent.stock_data_updater import handle_mcp_call as handle_updater_call
    from agent.stock_rising_calculator import handle_mcp_call as handle_calculator_call
    from agent.stock_concept_analyzer import handle_mcp_call as handle_analyzer_call
    
    if tool_name == "update_stock_data":
        return handle_updater_call(arguments)
    elif tool_name == "analyze_rising_stocks":
        return handle_calculator_call(arguments)
    elif tool_name == "analyze_concepts":
        return handle_analyzer_call(arguments)
    else:
        return {
            "content": [
                {
                    "type": "text",
                    "text": JsonUtil.dumps({"error": f"æœªçŸ¥å·¥å…·: {tool_name}"})
                }
            ],
            "isError": True
        }


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•° - CLIå…¥å£"""
    try:
        print("=" * 70)
        print("è‚¡ç¥¨æœç´¢å·¥å…· - å¼€å§‹æŸ¥è¯¢")
        print("=" * 70)
        
        result = search_rising_stocks(
            days=3, 
            market="all", 
            min_increase=10.0, 
            use_cache=False, 
            save_result=True,
            auto_update_cache=True,
            send_to_feishu=False
        )
        
        # æ‰“å°æŸ¥è¯¢ç»“æœæ¶ˆæ¯
        print(f"\næŸ¥è¯¢ç»“æœ: {result.get('message', 'N/A')}")
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if not result.get("success"):
            print("âŒ æŸ¥è¯¢å¤±è´¥")
            return
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨æ ¼æ•°æ®
        table_content = result.get("table", "")
        table_path = result.get("table_path")
        
        if table_path:
            print(f"âœ… è¡¨æ ¼æ•°æ®å·²ä¿å­˜åˆ°: {table_path}")
        
        # å¦‚æœæœ‰è¡¨æ ¼å†…å®¹ä¸”ä¸æ˜¯é”™è¯¯æ¶ˆæ¯ï¼Œæ‰“å°å‰å‡ è¡Œé¢„è§ˆ
        if table_content and table_content != "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨":
            print("\n" + "=" * 70)
            print("è¡¨æ ¼å†…å®¹é¢„è§ˆï¼ˆå‰30è¡Œï¼‰:")
            print("=" * 70)
            lines = table_content.split('\n')
            preview_lines = lines[:30]
            print('\n'.join(preview_lines))
            if len(lines) > 30:
                print(f"\n... (å…± {len(lines)} è¡Œï¼Œå®Œæ•´å†…å®¹è¯·æŸ¥çœ‹æ–‡ä»¶)")
            print("=" * 70)
        elif table_content == "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨":
            print("âš ï¸  æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        
        # æ‰“å°æ•°æ®ç»Ÿè®¡
        data = result.get("data", {})
        if data and isinstance(data, dict):
            stocks = data.get("stocks", [])
            if stocks:
                print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
                print(f"   - è‚¡ç¥¨æ•°é‡: {len(stocks)} åª")
                print(f"   - è¿æ¶¨å¤©æ•°: {data.get('rising_days', 'N/A')} å¤©")
                print(f"   - æŸ¥è¯¢æ—¶é—´: {data.get('query_time', 'N/A')}")
        
        print("\n" + "=" * 70)
        print("æŸ¥è¯¢å®Œæˆ")
        print("=" * 70)
        
    except Exception as e:
        logger.error(f"å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main()
