{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a69ce7",
   "metadata": {},
   "source": [
    "# learn_llm 4 周实践笔记本\n",
    "本笔记本按周组织：\n",
    "- Week1: 理论与注意力（NumPy 实现）\n",
    "- Week2: 工程与推理（Hugging Face pipeline 示例）\n",
    "- Week3: 微调示例（小数据、Trainer skeleton）\n",
    "- Week4: 部署（FastAPI 简易示例）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317bdbf",
   "metadata": {},
   "source": [
    "## 环境准备\n",
    "首次运行时请根据 README 先安装依赖：\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766c59e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape= (1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Week1: NumPy 实现的 Scaled Dot-Product Attention\n",
    "import numpy as np\n",
    "\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"\n",
    "    Q, K, V: (seq_len, d_k) 或 (batch, seq_len, d_k)\n",
    "    返回: attention 输出和 attention 权重\n",
    "    \"\"\"\n",
    "    # 简单的形状一致性检查，便于排错\n",
    "    if Q.ndim == 3:\n",
    "        # batch, seq_q, d_k ; batch, seq_k, d_k ; batch, seq_k, d_v\n",
    "        assert K.shape[1] == V.shape[1], f'K 和 V 的序列长度不一致: {K.shape[1]} vs {V.shape[1]}'\n",
    "    else:\n",
    "        assert K.shape[0] == V.shape[0], f'K 和 V 的序列长度不一致: {K.shape[0]} vs {V.shape[0]}'\n",
    "    # 计算 QK^T\n",
    "    scores = np.matmul(Q, K.transpose(0,2,1)) if Q.ndim==3 else np.dot(Q, K.T)\n",
    "    # 缩放\n",
    "    d_k = K.shape[-1]\n",
    "    scores = scores / np.sqrt(d_k)\n",
    "    # 可选 mask\n",
    "    if mask is not None:\n",
    "        scores = np.where(mask, scores, -1e9)\n",
    "    # softmax\n",
    "    if scores.ndim==3:\n",
    "        weights = np.exp(scores - np.max(scores, axis=-1, keepdims=True))\n",
    "        weights = weights / np.sum(weights, axis=-1, keepdims=True)\n",
    "        output = np.matmul(weights, V)\n",
    "    else:\n",
    "        exp = np.exp(scores - np.max(scores, axis=-1, keepdims=True))\n",
    "        weights = exp / np.sum(exp, axis=-1, keepdims=True)\n",
    "        output = np.dot(weights, V)\n",
    "    return output, weights\n",
    "\n",
    "# 小示例\n",
    "Q = np.array([[1.,0.,0.],[0.,1.,0.]])[None,:,:]  # (1,2,3)\n",
    "K = Q.copy()\n",
    "V = np.array([[1.,0.],[0.,1.]])[None,:,:]  # (1,2,2) 已修正与 Q/K 的序列长度匹配\n",
    "out, attn = scaled_dot_product_attention(Q, K, V)\n",
    "print('out.shape=', out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c50ae63",
   "metadata": {},
   "source": [
    "## Week2: Hugging Face 推理示例\n",
    "使用 pipeline 做快速文本生成（示例使用 distilgpt2）。首次运行会下载模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1394eb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05985c0be7a847209804b3a9120cf1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777a0ce7f4af482a92a37011eccb67bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35eae2385194584829f6dab047349a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde887ae3deb42ae96af133fd4d0ba9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b963ae412faa42bc9976bcde098cc856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb4f51bf7014461be448507b7976a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d79e798a2eb44cf82797e5b33bfddfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在未来的 AI 研究中，廝中，成的 AI 淯本的远与样品的其本定言着是这是不税地是对下良的莫的成的的国容容容的多以的详练良的地地的么罰廝良的是不安莫的成的一个成的发是了对了的不税地的多以的是汲貌化的汲是成的成的详练良以多的详练良的莫的成的地德练良的多以的来的详练良罰廝良的地的情以的发是汲貌化的是为�\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from transformers import pipeline\n",
    "    gen = pipeline('text-generation', model='distilgpt2')\n",
    "    res = gen('在未来的 AI 研究中，', max_length=40, num_return_sequences=1)\n",
    "    print(res[0]['generated_text'])\n",
    "except Exception as e:\n",
    "    print('无法加载 transformers 或 下载模型失败，运行前请确保依赖已安装并可联网。', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c8c9b",
   "metadata": {},
   "source": [
    "## Week3: 微调示例（数据准备与 Trainer skeleton）\n",
    "演示如何构建小数据集并进行 tokenization，给出 Trainer 的最小骨架（不必实际训练大模型）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4be51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b348f622cb84e2abb8390627353264e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "示例 tokenized: {'text': '今天天气很好', 'input_ids': [20015, 232, 25465, 25465, 36365, 242, 36181, 230, 25001, 121, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from datasets import Dataset\n",
    "    from transformers import AutoTokenizer\n",
    "    # 准备小数据集\n",
    "    raw = {'text': ['今天天气很好', '机器学习很有意思', '深度学习是强大的工具']}\n",
    "    ds = Dataset.from_dict(raw)\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "    # 若 tokenizer 没有 pad_token，则优先使用 eos_token 作为 pad_token，否则新增 [PAD]\n",
    "    if getattr(tokenizer, 'pad_token', None) is None:\n",
    "        if getattr(tokenizer, 'eos_token', None) is not None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        else:\n",
    "            tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    def tokenize_fn(ex):\n",
    "        return tokenizer(ex['text'], truncation=True, padding='max_length', max_length=32)\n",
    "    tok_ds = ds.map(lambda x: tokenize_fn(x), batched=True)\n",
    "    print('示例 tokenized:', tok_ds[0])\n",
    "except Exception as e:\n",
    "    print('datasets/tokenizer 示例无法运行：', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180670b",
   "metadata": {},
   "source": [
    "## Week4: 部署示例（FastAPI）\n",
    "下面写出一个最小 FastAPI app 的样例代码，将模型包装为 /generate 接口。可单独保存为 app.py 并用 uvicorn 运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba98338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已写出 app.py，运行: uvicorn app:app --reload\n"
     ]
    }
   ],
   "source": [
    "fastapi_app_code = '''\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    gen = pipeline('text-generation', model='distilgpt2')\n",
    "except Exception:\n",
    "    gen = None\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class Req(BaseModel):\n",
    "    prompt: str\n",
    "\n",
    "@app.post('/generate')\n",
    "def generate(req: Req):\n",
    "    if gen is None:\n",
    "        return {'error': '模型未加载，检查依赖或网络'}\n",
    "    out = gen(req.prompt, max_length=50, num_return_sequences=1)\n",
    "    return {'text': out[0]['generated_text']}\n",
    "'''\n",
    "\n",
    "with open('app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(fastapi_app_code)\n",
    "print('已写出 app.py，运行: uvicorn app:app --reload')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2332ca",
   "metadata": {},
   "source": [
    "---\n",
    "提示：笔记本中的示例以教学为主，实际训练/部署请根据显存与计算资源调整模型、批次与训练步数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
