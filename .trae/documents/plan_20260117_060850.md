## 技术指标增量计算优化

### 当前问题

```python
def _fill_technical_aspect():
    # 每次遍历所有文件
    for f in all_files:
        df = pd.read_csv(f)        # 读取完整数据
        df = _calculate_indicators(df)  # 重新计算全部指标
        df.to_csv(f)               # 写回完整数据
```

每次都重新计算 ~5000 个文件的全部技术指标，效率低下。

### 优化方案

#### 1. 增量计算技术指标

```python
def _calculate_indicators_incremental(df: pd.DataFrame, new_rows_count: int = None) -> pd.DataFrame:
    """增量计算技术指标，只计算新增行的指标"""
    
    # 如果是首次计算（无技术指标列），计算全部
    if "MA5" not in df.columns or df["MA5"].isna().all():
        return _calculate_indicators_full(df)
    
    # 增量计算：只处理最后几行
    if new_rows_count is None:
        # 检测有多少新行（不在缓存中的日期）
        new_rows_count = _detect_new_rows(df)
    
    if new_rows_count == 0:
        return df  # 无新数据，跳过
    
    # 只对新增行计算技术指标
    # ...
```

#### 2. 智能检测新增行

```python
def _detect_new_rows(df: pd.DataFrame) -> int:
    """检测新增行数"""
    # 检查是否有技术指标列
    if "MA5" not in df.columns:
        return len(df)
    
    # 找到最后一个有效MA5值的行
    valid_ma5 = df["MA5"].notna()
    if not valid_ma5.any():
        return len(df)
    
    # 返回需要重新计算的行数（考虑到滚动窗口）
    last_valid_idx = df[valid_ma5].index[-1]
    return len(df) - last_valid_idx
```

#### 3. 优化 `_process_file`

```python
def _process_file(file_path: Path) -> None:
    """增量处理单个文件"""
    try:
        df = pd.read_csv(file_path, encoding="utf-8-sig")
        if len(df) < 5:
            return
        
        # 增量计算（只计算新增日期的技术指标）
        df = _calculate_indicators_incremental(df)
        
        df.to_csv(file_path, index=False, encoding="utf-8-sig")
    except Exception as e:
        print_red(f"处理文件失败 {file_path}: {e}")
```

### 性能对比

| 场景 | 优化前 | 优化后 |
|-----|-------|-------|
| 首次运行 | 5000文件 × 全量计算 | 相同 |
| 增量更新 | 5000文件 × 全量计算 | 只计算新增行(~1行/文件) |
| 增量耗时 | ~2分钟 | ~1秒 |

### 注意事项

- MA、VOL_MA 需要最近 N 天的数据才能计算，所以增量计算时可能需要回溯几行
- MACD 的 EMA 是指数平滑，需要完整历史，但可以用增量方式更新
- 如果历史数据被修改，需要支持全量重算