## 数据获取优化方案

### 核心思路

1. **增量更新**：只获取缺失的日期，避免重复请求
2. **智能缓存**：行业映射、利润表等缓存到独立文件
3. **停牌容错**：缺失数据 < 20% 视为正常停牌，跳过获取

### 实现步骤

#### 步骤1: 增强 `data_path_util.py`

```python
# 新增缓存文件路径
get_industry_cache_file()     # 行业映射缓存
get_lrb_cache_file()          # 利润表缓存

# 新增缓存管理函数
_is_cache_expired(path, days) # 检查缓存是否过期
load_cache(path)              # 加载缓存
save_cache(data, path)        # 保存缓存
```

#### 步骤2: 优化 `load_base_data.py`

**行业映射缓存（7天过期）**：

```python
def _fetch_industry_mapping():
    cache = get_industry_cache_file()
    if cache.exists() and not _is_cache_expired(cache, days=7):
        return load_cache(cache)
    data = _fetch_from_api()
    save_cache(data, cache)
    return data
```

**利润表缓存（30天过期）**：

```python
def _fetch_lrb_data():
    cache = get_lrb_cache_file()
    if cache.exists() and not _is_cache_expired(cache, days=30):
        return load_cache(cache)
    data = _fetch_from_api()  # 使用最近季度
    save_cache(data, cache)
    return data
```

**停牌容错的缺失检测**：

```python
def _has_missing_days(cache_file, trading_days):
    cached = pd.read_csv(cache_file, parse_dates=['日期'])
    local_dates = set(cached['日期'].dt.strftime('%Y%m%d'))
    missing = [d for d in trading_days if d not in local_dates]
    
    # 缺失 < 20% 视为停牌，跳过更新
    if len(missing) / len(trading_days) < 0.2:
        return False
    return len(missing) > 0
```

### 性能对比

| 场景   | 优化前     | 优化后       |
| ---- | ------- | --------- |
| 首次运行 | 请求全部API | 不变        |
| 增量更新 | 匹配则不请求  | 相同 + 停牌容错 |
| 行业映射 | 每次重新获取  | 缓存7天      |
| 利润表  | 每次重新获取  | 缓存30天     |

### 预期效果

* 行业映射获取从 \~10s → 首次10s，后续0.1s

* 利润表获取从 \~5s → 首次5s，后续0.1s

* 停牌股票不再重复请求API

